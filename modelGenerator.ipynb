{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_fqMmEbenDc",
        "outputId": "7d24a229-cb46-493c-eaaa-df2356359374"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48OJwM6Pao4n"
      },
      "source": [
        "# Import and function definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD9sWdFCu_qM",
        "outputId": "4652e759-3046-45ea-8b36-3362269d0663"
      },
      "outputs": [],
      "source": [
        "# Download and import visualkeras and keras-tuner library\n",
        "!pip install visualkeras\n",
        "!pip install keras-tuner -q\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnTeg3aVenDf"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "from keras import Model\n",
        "from PIL import Image\n",
        "import keras_tuner\n",
        "from sklearn.model_selection import KFold\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tFnzOOfa0vZ"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 96\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "\n",
        "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
        "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
        "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
        "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def get_box(lambda_value):\n",
        "    cut_rat = tf.math.sqrt(1.0 - lambda_value)\n",
        "\n",
        "    cut_w = IMG_SIZE * cut_rat  # rw\n",
        "    cut_w = tf.cast(cut_w, tf.int32)\n",
        "\n",
        "    cut_h = IMG_SIZE * cut_rat  # rh\n",
        "    cut_h = tf.cast(cut_h, tf.int32)\n",
        "\n",
        "    cut_x = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # rx\n",
        "    cut_y = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # ry\n",
        "\n",
        "    boundaryx1 = tf.clip_by_value(cut_x[0] - cut_w // 2, 0, IMG_SIZE)\n",
        "    boundaryy1 = tf.clip_by_value(cut_y[0] - cut_h // 2, 0, IMG_SIZE)\n",
        "    bbx2 = tf.clip_by_value(cut_x[0] + cut_w // 2, 0, IMG_SIZE)\n",
        "    bby2 = tf.clip_by_value(cut_y[0] + cut_h // 2, 0, IMG_SIZE)\n",
        "\n",
        "    target_h = bby2 - boundaryy1\n",
        "    if target_h == 0:\n",
        "        target_h += 1\n",
        "\n",
        "    target_w = bbx2 - boundaryx1\n",
        "    if target_w == 0:\n",
        "        target_w += 1\n",
        "\n",
        "    return boundaryx1, boundaryy1, target_h, target_w\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def cutmix(train_ds_one, train_ds_two):\n",
        "    (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n",
        "\n",
        "    alpha = [0.25]\n",
        "    beta = [0.25]\n",
        "\n",
        "    # Get a sample from the Beta distribution\n",
        "    lambda_value = sample_beta_distribution(1, alpha, beta)\n",
        "\n",
        "    # Define Lambda\n",
        "    lambda_value = lambda_value[0][0]\n",
        "\n",
        "    # Get the bounding box offsets, heights and widths\n",
        "    boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n",
        "\n",
        "    # Get a patch from the second image (`image2`)\n",
        "    crop2 = tf.image.crop_to_bounding_box(\n",
        "        image2, boundaryy1, boundaryx1, target_h, target_w\n",
        "    )\n",
        "    # Pad the `image2` patch (`crop2`) with the same offset\n",
        "    image2 = tf.image.pad_to_bounding_box(\n",
        "        crop2, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n",
        "    )\n",
        "    # Get a patch from the first image (`image1`)\n",
        "    crop1 = tf.image.crop_to_bounding_box(\n",
        "        image1, boundaryy1, boundaryx1, target_h, target_w\n",
        "    )\n",
        "    # Pad the `image1` patch (`crop1`) with the same offset\n",
        "    img1 = tf.image.pad_to_bounding_box(\n",
        "        crop1, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n",
        "    )\n",
        "\n",
        "    # Modify the first image by subtracting the patch from `image1`\n",
        "    # (before applying the `image2` patch)\n",
        "    image1 = image1 - img1\n",
        "    # Add the modified `image1` and `image2`  together to get the CutMix image\n",
        "    image = image1 + image2\n",
        "\n",
        "    # Adjust Lambda in accordance to the pixel ration\n",
        "    lambda_value = 1 - (target_w * target_h) / (IMG_SIZE * IMG_SIZE)\n",
        "    lambda_value = tf.cast(lambda_value, tf.float32)\n",
        "\n",
        "    # Combine the labels of both images\n",
        "    label = lambda_value * label1 + (1 - lambda_value) * label2\n",
        "    return image, label\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhhcYDKoenDg"
      },
      "outputs": [],
      "source": [
        "def load_data(path, labels):\n",
        "    # Dataset folders\n",
        "    dataset_dir = path\n",
        "\n",
        "    gen = ImageDataGenerator().flow_from_directory(directory=dataset_dir,\n",
        "                                               target_size=(IMG_SIZE,IMG_SIZE),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=None, # can be set to labels or None\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=batchSize,\n",
        "                                               shuffle=True,\n",
        "                                               seed=seed)\n",
        "    \n",
        "\n",
        "    return gen\n",
        "\n",
        "def processing_data(data, labels):\n",
        "\n",
        "    X,Y = data.next()\n",
        "    \n",
        "    check_image = os.path.exists('/gdrive/My Drive/images.npy')\n",
        "    check_target = os.path.exists('/gdrive/My Drive/targets.npy')\n",
        "    if(check_image and check_target):\n",
        "      X = np.load('images.npy')\n",
        "      Y = np.load('targets.npy')\n",
        "    else:\n",
        "      for i in tqdm(range(data.__len__())):\n",
        "        images, targets = data.next()\n",
        "        X = np.concatenate((X, images), axis = 0)\n",
        "        Y = np.concatenate((Y, targets), axis = 0)\n",
        "      np.save('images.npy', X)\n",
        "      np.save('targets.npy', Y)\n",
        "    \n",
        "    \n",
        "    Xtest = X[0]\n",
        "    Ytest = Y[0]\n",
        "    Xtrain = X[0]\n",
        "    Ytrain = Y[0]\n",
        "    Xval = X[0]\n",
        "    Yval = Y[0]\n",
        "    XvalTuner = X[0]\n",
        "    YvalTuner = Y[0]\n",
        "\n",
        "    print(\"total size: \"+str(X.shape)+\" \"+str(Y.shape))\n",
        "\n",
        "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=paramSplit, random_state=seed, stratify=Y)\n",
        "    Xtest, Xval, Ytest, Yval = train_test_split(Xtest,Ytest, test_size=(2/3), random_state=seed, stratify=Ytest)\n",
        "    Xval, XvalTuner, Yval, YvalTuner = train_test_split(Xval,Yval, test_size=0.5, random_state=seed, stratify=Yval)\n",
        "\n",
        "    #Normalize the data like supernet\n",
        "    Xtrain = tf.keras.applications.vgg16.preprocess_input(Xtrain)\n",
        "    Xval = tf.keras.applications.vgg16.preprocess_input(Xval)\n",
        "    XvalTuner = tf.keras.applications.vgg16.preprocess_input(XvalTuner)\n",
        "    Xtest = tf.keras.applications.vgg16.preprocess_input(Xtest)\n",
        "\n",
        "    shapeBeforeDA = str(Xtrain.shape)+\" \"+str(Ytrain.shape)\n",
        "\n",
        "    #Data augmentation cutmix\n",
        "    check_image = os.path.exists('/gdrive/My Drive/imagesDA.npy')\n",
        "    check_target = os.path.exists('/gdrive/My Drive/targetsDA.npy')\n",
        "    if(check_image and check_target):\n",
        "       Xtrain = np.load('imagesDA.npy')\n",
        "       Ytrain = np.load('targetsDA.npy')\n",
        "    else:\n",
        "\n",
        "      train_ds_one = (\n",
        "          tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain))\n",
        "          .shuffle(1024)\n",
        "          .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "      )\n",
        "      train_ds_two = (\n",
        "          tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain))\n",
        "          .shuffle(1024)\n",
        "          .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "      )\n",
        "\n",
        "      train_ds_simple = tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain))\n",
        "\n",
        "      test_ds = tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain))\n",
        "\n",
        "      train_ds_simple = (\n",
        "          train_ds_simple.map(preprocess_image, num_parallel_calls=AUTO)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .prefetch(AUTO)\n",
        "      )\n",
        "\n",
        "      # Combine two shuffled datasets from the same training data.\n",
        "      train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
        "\n",
        "      test_ds = (\n",
        "          test_ds.map(preprocess_image, num_parallel_calls=AUTO)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .prefetch(AUTO)\n",
        "      )\n",
        "\n",
        "      train_ds_cmu = (\n",
        "          train_ds.shuffle(1024)\n",
        "          .map(cutmix, num_parallel_calls=AUTO)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .prefetch(AUTO)\n",
        "      )\n",
        "      #Normal Data Aumentation\n",
        "      gen = ImageDataGenerator(rotation_range=360,\n",
        "                              height_shift_range=0.3,\n",
        "                              width_shift_range=0.3,\n",
        "                              zoom_range=0.9,\n",
        "                              horizontal_flip=True,\n",
        "                              vertical_flip=True, \n",
        "                              fill_mode='reflect',\n",
        "                              brightness_range=[0.5,1.5])\n",
        "      \n",
        "      img_shape=Xtrain.shape[1:]\n",
        "\n",
        "      #Concatenation\n",
        "      for i, image in tqdm(enumerate(Xtrain)):\n",
        "        trasformation = gen.get_random_transform(img_shape=img_shape, seed=seed)\n",
        "        new_image = gen.apply_transform(image, trasformation)\n",
        "        new_image = np.expand_dims(new_image, axis = 0)\n",
        "        target = np.expand_dims(Ytrain[i], axis = 0)\n",
        "        \n",
        "        Xtrain = np.concatenate((Xtrain, new_image), axis = 0)\n",
        "        Ytrain = np.concatenate((Ytrain, target), axis = 0)\n",
        "\n",
        "    \n",
        "      for image_batch, label_batch in tqdm(iter(train_ds_cmu)):\n",
        "          Xtrain = np.concatenate((Xtrain, image_batch), axis = 0)\n",
        "          Ytrain = np.concatenate((Ytrain, label_batch), axis = 0)\n",
        "\n",
        "      np.save('imagesDA.npy', Xtrain)\n",
        "      np.save('targetsDA.npy', Ytrain)\n",
        "        \n",
        "    print(\"\\ntrain pre-augm  size: \"+shapeBeforeDA)\n",
        "    print(\"train post-augm size: \"+str(Xtrain.shape)+\" \"+str(Ytrain.shape))\n",
        "    print(\"test            size: \"+str(Xtest.shape)+\" \"+str(Ytest.shape))\n",
        "    print(\"val             size: \"+str(Xval.shape)+\" \"+str(Yval.shape)) \n",
        "    print(\"val tuner       size: \"+str(XvalTuner.shape)+\" \"+str(YvalTuner.shape)) \n",
        "\n",
        "    return Xtest, Ytest, Xtrain, Ytrain, Xval, Yval, XvalTuner, YvalTuner\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    supernet = tfk.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_shape,\n",
        "    classifier_activation=\"softmax\"\n",
        "    )\n",
        "    \n",
        "    inputs = tfk.Input(shape=(input_shape))\n",
        "    x = supernet( inputs )\n",
        "\n",
        "    if hp.Boolean(\"global?\"):\n",
        "      x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    else:\n",
        "      x = tfkl.Flatten(name='Flattening')(x)\n",
        "    \n",
        "    x = tfkl.Dropout(0.3, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense( \n",
        "        units = hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "        activation='relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed))(x)\n",
        "\n",
        "      # Tune whether to use dropout.\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "          x = tfkl.Dropout(0.3, seed=seed )(x)\n",
        "    \n",
        "    outputs = tfkl.Dense(\n",
        "        8, \n",
        "        activation='softmax',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
        "\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model = compile_model(model,hp)\n",
        "                      \n",
        "    # Return the model\n",
        "    return model\n",
        "\n",
        "def compile_model(model,hp):\n",
        "    momentum = 0.9\n",
        "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-3, sampling=\"log\")\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate), metrics='accuracy')\n",
        "\n",
        "    # Compile the model with a SGD/momentum optimizer\n",
        "    #model.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), metrics=['accuracy'])\n",
        "\n",
        "    # Return the model\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HSs9n-0NswN"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCxc3PeZenDh",
        "outputId": "a8728b0f-7090-48dd-a907-c40b536cd96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3542 images belonging to 8 classes.\n",
            "total size: (4054, 96, 96, 3) (4054, 8)\n",
            "\n",
            "train pre-augm  size: (2837, 96, 96, 3) (2837, 8)\n",
            "train post-augm size: (8511, 96, 96, 3) (8511, 8)\n",
            "test            size: (405, 96, 96, 3) (405, 8)\n",
            "val             size: (406, 96, 96, 3) (406, 8)\n",
            "val tuner       size: (406, 96, 96, 3) (406, 8)\n"
          ]
        }
      ],
      "source": [
        "paramSplit = 0.3\n",
        "seed = 42\n",
        "batchSize = BATCH_SIZE\n",
        "num_folds = 10\n",
        "path = \"dataset\"\n",
        "\n",
        "hp = keras_tuner.HyperParameters()\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "labels = ['Species1',       # 0\n",
        "          'Species2',       # 1\n",
        "          'Species3',       # 2\n",
        "          'Species4',       # 3\n",
        "          'Species5',       # 4\n",
        "          'Species6',       # 5\n",
        "          'Species7',       # 6\n",
        "          'Species8' ]      # 7\n",
        "\n",
        "# Random seed for reproducibility\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Load data from folder\n",
        "data = load_data(path, labels)\n",
        "\n",
        "# Spitting data and normalization\n",
        "Xtest, Ytest, Xtrain, Ytrain, Xval, Yval, XvalTuner, YvalTuner = processing_data(data,labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_6UyxgsuupI",
        "outputId": "105e9301-9619-4ffb-a499-6574ba5ff3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 03m 49s]\n",
            "val_accuracy: 0.5829228162765503\n",
            "\n",
            "Best val_accuracy So Far: 0.6026272575060526\n",
            "Total elapsed time: 01h 20m 09s\n",
            "Results summary\n",
            "Results in Tuner/RIC tuner VGG16\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fb90aaabd90>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.6026272575060526\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.6009852091471354\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5977011521657308\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5960591038068136\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5944170753161112\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5903119842211405\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5862068931261698\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5853858788808187\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5837438503901163\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "global?: False\n",
            "units: 32\n",
            "dropout: False\n",
            "learning_rate: 0.0001\n",
            "Score: 0.5829228162765503\n"
          ]
        }
      ],
      "source": [
        "input_shape = Xtrain.shape[1:]\n",
        "epochs = 3\n",
        "\n",
        "#Fine tuning &/or tranfer learning\n",
        "base_model_name = 'vgg16'\n",
        "\n",
        "base_model = tfk.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_shape,\n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "\n",
        "#Setting tuner\n",
        "tuner = keras_tuner.BayesianOptimization( #Can be RandomSearch, BayesianOptimization or Hyperband\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\", \n",
        "    max_trials=20,\n",
        "    executions_per_trial=3,\n",
        "    overwrite = True, # False = restore result / True = new run\n",
        "    directory=\"Tuner\", \n",
        "    project_name=\"RIC tuner VGG16\",\n",
        ")\n",
        "\n",
        "# Building model\n",
        "model = build_model(hp)\n",
        "\n",
        "visualkeras.layered_view(base_model, legend=True, spacing=20, scale_xy=5)\n",
        "\n",
        "# Search for the best hyperparameter\n",
        "tuner.search(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    batch_size = batchSize,\n",
        "    epochs = epochs,\n",
        "    validation_data = (XvalTuner, YvalTuner),\n",
        ")\n",
        "\n",
        "\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STMuq6YFihzY",
        "outputId": "9a069e53-c2a7-4669-8f82-ab70bd1f746e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " Flattening (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                147488    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,862,440\n",
            "Trainable params: 14,862,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get the top 2 models.\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "\n",
        "# Build the model.\n",
        "best_model.build(input_shape=input_shape)\n",
        "best_model.summary()\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhSSsAKpNjZ_"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "620ZeQg_u1hk",
        "outputId": "bdc9fc50-ae6b-4316-b643-acefb14d2f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " Flattening (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                147488    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,862,440\n",
            "Trainable params: 14,602,280\n",
            "Non-trainable params: 260,160\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "17/17 [==============================] - 15s 863ms/step - loss: 2.1460 - accuracy: 0.2926 - val_loss: 1.5382 - val_accuracy: 0.3818\n",
            "Epoch 2/40\n",
            "17/17 [==============================] - 15s 862ms/step - loss: 1.6082 - accuracy: 0.3763 - val_loss: 1.2823 - val_accuracy: 0.5172\n",
            "Epoch 3/40\n",
            "17/17 [==============================] - 15s 872ms/step - loss: 1.4389 - accuracy: 0.4540 - val_loss: 1.0844 - val_accuracy: 0.5887\n",
            "Epoch 4/40\n",
            "17/17 [==============================] - 15s 863ms/step - loss: 1.3037 - accuracy: 0.5189 - val_loss: 0.9795 - val_accuracy: 0.6379\n",
            "Epoch 5/40\n",
            "17/17 [==============================] - 15s 861ms/step - loss: 1.2113 - accuracy: 0.5558 - val_loss: 0.8800 - val_accuracy: 0.6626\n",
            "Epoch 6/40\n",
            "17/17 [==============================] - 15s 860ms/step - loss: 1.1450 - accuracy: 0.5902 - val_loss: 0.8722 - val_accuracy: 0.6798\n",
            "Epoch 7/40\n",
            "17/17 [==============================] - 15s 861ms/step - loss: 1.0705 - accuracy: 0.6160 - val_loss: 0.8339 - val_accuracy: 0.7044\n",
            "Epoch 8/40\n",
            "17/17 [==============================] - 15s 864ms/step - loss: 0.9999 - accuracy: 0.6557 - val_loss: 0.7591 - val_accuracy: 0.7266\n",
            "Epoch 9/40\n",
            "17/17 [==============================] - 15s 864ms/step - loss: 0.9137 - accuracy: 0.6871 - val_loss: 0.6923 - val_accuracy: 0.7562\n",
            "Epoch 10/40\n",
            "17/17 [==============================] - 15s 868ms/step - loss: 0.8450 - accuracy: 0.7234 - val_loss: 0.6626 - val_accuracy: 0.7734\n",
            "Epoch 11/40\n",
            "17/17 [==============================] - 15s 870ms/step - loss: 0.7490 - accuracy: 0.7520 - val_loss: 0.5902 - val_accuracy: 0.8103\n",
            "Epoch 12/40\n",
            "17/17 [==============================] - 15s 868ms/step - loss: 0.6809 - accuracy: 0.7839 - val_loss: 0.6332 - val_accuracy: 0.8079\n",
            "Epoch 13/40\n",
            "17/17 [==============================] - 15s 865ms/step - loss: 0.6581 - accuracy: 0.7931 - val_loss: 0.7224 - val_accuracy: 0.7167\n",
            "Epoch 14/40\n",
            "17/17 [==============================] - 15s 865ms/step - loss: 0.6266 - accuracy: 0.8019 - val_loss: 0.6750 - val_accuracy: 0.7833\n",
            "Epoch 15/40\n",
            "17/17 [==============================] - 15s 865ms/step - loss: 0.5409 - accuracy: 0.8357 - val_loss: 0.5643 - val_accuracy: 0.8079\n",
            "Epoch 16/40\n",
            "17/17 [==============================] - 15s 868ms/step - loss: 0.4592 - accuracy: 0.8701 - val_loss: 0.6269 - val_accuracy: 0.8424\n",
            "Epoch 17/40\n",
            "17/17 [==============================] - 15s 867ms/step - loss: 0.4367 - accuracy: 0.8751 - val_loss: 0.6451 - val_accuracy: 0.8276\n",
            "Epoch 18/40\n",
            "17/17 [==============================] - 15s 872ms/step - loss: 0.3863 - accuracy: 0.8966 - val_loss: 0.7210 - val_accuracy: 0.8473\n",
            "Epoch 19/40\n",
            "17/17 [==============================] - 15s 869ms/step - loss: 0.3532 - accuracy: 0.9114 - val_loss: 0.7182 - val_accuracy: 0.8128\n",
            "Epoch 20/40\n",
            "17/17 [==============================] - 15s 874ms/step - loss: 0.3403 - accuracy: 0.9136 - val_loss: 0.6878 - val_accuracy: 0.8498\n",
            "Epoch 21/40\n",
            "17/17 [==============================] - 15s 876ms/step - loss: 0.2973 - accuracy: 0.9303 - val_loss: 0.7771 - val_accuracy: 0.8547\n",
            "Epoch 22/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.3132 - accuracy: 0.9268 - val_loss: 0.7928 - val_accuracy: 0.8030\n",
            "Epoch 23/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.3474 - accuracy: 0.9121 - val_loss: 0.8809 - val_accuracy: 0.8399\n",
            "Epoch 24/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2994 - accuracy: 0.9297 - val_loss: 0.9452 - val_accuracy: 0.8374\n",
            "Epoch 25/40\n",
            "17/17 [==============================] - 15s 877ms/step - loss: 0.2583 - accuracy: 0.9431 - val_loss: 0.7746 - val_accuracy: 0.8571\n",
            "Epoch 26/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2363 - accuracy: 0.9552 - val_loss: 0.9512 - val_accuracy: 0.8300\n",
            "Epoch 27/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2163 - accuracy: 0.9559 - val_loss: 0.8595 - val_accuracy: 0.8498\n",
            "Epoch 28/40\n",
            "17/17 [==============================] - 15s 874ms/step - loss: 0.2070 - accuracy: 0.9568 - val_loss: 0.9146 - val_accuracy: 0.8498\n",
            "Epoch 29/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2041 - accuracy: 0.9592 - val_loss: 1.1891 - val_accuracy: 0.8473\n",
            "Epoch 30/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.1979 - accuracy: 0.9622 - val_loss: 1.3367 - val_accuracy: 0.8399\n",
            "Epoch 31/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2053 - accuracy: 0.9598 - val_loss: 1.2834 - val_accuracy: 0.8522\n",
            "Epoch 32/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.2072 - accuracy: 0.9563 - val_loss: 0.8701 - val_accuracy: 0.8498\n",
            "Epoch 33/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.1976 - accuracy: 0.9582 - val_loss: 1.0054 - val_accuracy: 0.8424\n",
            "Epoch 34/40\n",
            "17/17 [==============================] - 15s 871ms/step - loss: 0.1907 - accuracy: 0.9568 - val_loss: 0.9465 - val_accuracy: 0.8498\n",
            "Epoch 35/40\n",
            "17/17 [==============================] - 15s 873ms/step - loss: 0.1843 - accuracy: 0.9612 - val_loss: 1.0608 - val_accuracy: 0.8498\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " Flattening (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                147488    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,862,440\n",
            "Trainable params: 14,862,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "17/17 [==============================] - 24s 1s/step - loss: 1.9424 - accuracy: 0.5507 - val_loss: 1.0706 - val_accuracy: 0.6256\n",
            "Epoch 2/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 1.0345 - accuracy: 0.6439 - val_loss: 0.8359 - val_accuracy: 0.7192\n",
            "Epoch 3/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.7721 - accuracy: 0.7484 - val_loss: 0.7141 - val_accuracy: 0.7734\n",
            "Epoch 4/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.5511 - accuracy: 0.8289 - val_loss: 0.7269 - val_accuracy: 0.8103\n",
            "Epoch 5/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3998 - accuracy: 0.8919 - val_loss: 0.7506 - val_accuracy: 0.8251\n",
            "Epoch 6/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3216 - accuracy: 0.9206 - val_loss: 0.8279 - val_accuracy: 0.8227\n",
            "Epoch 7/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3007 - accuracy: 0.9273 - val_loss: 0.7643 - val_accuracy: 0.8448\n",
            "Epoch 8/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2676 - accuracy: 0.9397 - val_loss: 0.9720 - val_accuracy: 0.8350\n",
            "Epoch 9/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2499 - accuracy: 0.9472 - val_loss: 0.9940 - val_accuracy: 0.8374\n",
            "Epoch 10/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2292 - accuracy: 0.9517 - val_loss: 1.0169 - val_accuracy: 0.8621\n",
            "Epoch 11/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2112 - accuracy: 0.9602 - val_loss: 1.1047 - val_accuracy: 0.8448\n",
            "Epoch 12/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2000 - accuracy: 0.9606 - val_loss: 1.1037 - val_accuracy: 0.8276\n",
            "Epoch 13/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1989 - accuracy: 0.9626 - val_loss: 1.1442 - val_accuracy: 0.8621\n",
            "Epoch 14/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1910 - accuracy: 0.9623 - val_loss: 1.2752 - val_accuracy: 0.8424\n",
            "Epoch 15/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1863 - accuracy: 0.9639 - val_loss: 1.0515 - val_accuracy: 0.8621\n",
            "Epoch 16/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1824 - accuracy: 0.9643 - val_loss: 1.2602 - val_accuracy: 0.8300\n",
            "Epoch 17/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1784 - accuracy: 0.9619 - val_loss: 1.3242 - val_accuracy: 0.8719\n",
            "Epoch 18/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1808 - accuracy: 0.9603 - val_loss: 1.2086 - val_accuracy: 0.8399\n",
            "Epoch 19/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1746 - accuracy: 0.9615 - val_loss: 1.2920 - val_accuracy: 0.8596\n",
            "Epoch 20/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1717 - accuracy: 0.9593 - val_loss: 1.3757 - val_accuracy: 0.8498\n",
            "Epoch 21/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1786 - accuracy: 0.9585 - val_loss: 1.1049 - val_accuracy: 0.8374\n",
            "Epoch 22/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1708 - accuracy: 0.9609 - val_loss: 1.0815 - val_accuracy: 0.8424\n",
            "Epoch 23/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1691 - accuracy: 0.9602 - val_loss: 1.1083 - val_accuracy: 0.8670\n",
            "Epoch 24/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1645 - accuracy: 0.9617 - val_loss: 1.1644 - val_accuracy: 0.8571\n",
            "Epoch 25/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1600 - accuracy: 0.9585 - val_loss: 1.2262 - val_accuracy: 0.8571\n",
            "Epoch 26/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1581 - accuracy: 0.9633 - val_loss: 1.3769 - val_accuracy: 0.8473\n",
            "Epoch 27/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1588 - accuracy: 0.9638 - val_loss: 1.3126 - val_accuracy: 0.8547\n",
            "Epoch 28/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1618 - accuracy: 0.9610 - val_loss: 1.2902 - val_accuracy: 0.8448\n",
            "Epoch 29/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1744 - accuracy: 0.9551 - val_loss: 1.2113 - val_accuracy: 0.8374\n",
            "Epoch 30/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4817 - accuracy: 0.8658 - val_loss: 0.9225 - val_accuracy: 0.8103\n",
            "Epoch 31/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3384 - accuracy: 0.9039 - val_loss: 1.1347 - val_accuracy: 0.8054\n",
            "Epoch 32/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2418 - accuracy: 0.9389 - val_loss: 1.1860 - val_accuracy: 0.8399\n",
            "Epoch 33/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2011 - accuracy: 0.9528 - val_loss: 1.0982 - val_accuracy: 0.8350\n",
            "Epoch 34/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1849 - accuracy: 0.9588 - val_loss: 1.2850 - val_accuracy: 0.8325\n",
            "Epoch 35/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2089 - accuracy: 0.9445 - val_loss: 0.9020 - val_accuracy: 0.8424\n",
            "Epoch 36/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1738 - accuracy: 0.9589 - val_loss: 1.1550 - val_accuracy: 0.8621\n",
            "Epoch 37/400\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1657 - accuracy: 0.9597 - val_loss: 1.2233 - val_accuracy: 0.8547\n"
          ]
        }
      ],
      "source": [
        "epochs = 400\n",
        "\n",
        "model = best_model\n",
        "\n",
        "# Freeze N layers\n",
        "setNotTrainable = [0, 1, 2, 3, 4, 5, 6]\n",
        "\n",
        "model.get_layer(base_model_name).trainable = True\n",
        "\n",
        "for i, layer in enumerate(model.get_layer(base_model_name).layers):\n",
        "  if i in setNotTrainable:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model,best_hps[0])\n",
        "model.summary()\n",
        "\n",
        "# Fitting model\n",
        "history = model.fit(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    batch_size = batchSize,\n",
        "    epochs = int(epochs/10),\n",
        "    validation_data = (Xval, Yval),\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
        ").history\n",
        "\n",
        "\n",
        "# Sfreeze N layers\n",
        "model.get_layer(base_model_name).trainable = True\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model,best_hps[0]) \n",
        "model.summary()\n",
        "\n",
        "# Second Fitting model\n",
        "history = model.fit(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    batch_size = batchSize,\n",
        "    epochs = epochs,\n",
        "    validation_data = (Xval, Yval),\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-WyvFwmvoiP"
      },
      "outputs": [],
      "source": [
        "# Plot the training\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Binary Crossentropy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Compute the confusion matrix\n",
        "predictions = model.predict(Xtest)\n",
        "cm = confusion_matrix(np.argmax(Ytest, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "#Kfold validation\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "score = model.evaluate(Xtest, Ytest)\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Ytest, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Ytest, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Ytest, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Ytest, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "print('Loss:', score[0])\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "# Plot the confusion matrix\n",
        "sns.heatmap(cm.T, xticklabels=list(labels), yticklabels=list(labels))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tvR_OuKsIA0",
        "outputId": "c2813189-65ef-4304-d39b-f1502d2bdba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/gdrive/Othercomputers/Il mio MacBook Air/Challenge1/Good model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/Good\\ model\n",
        "model.save(\"ModelAccuracy\"+(\"{:.1f}\".format(score[1]*100))+\"%\"+base_model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
